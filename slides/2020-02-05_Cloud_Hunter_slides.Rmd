---
title: "The Cloud Hunter’s Problem"
subtitle: "An Automated Decision Algorithm to Improve the Productivity of Scientific Data Collection in Stochastic Environments"
author: "Arthur Small"
institute: "based on work with JASON B. STEFIK, JOHANNES VERLINDE, NATHANIEL C. JOHNSON"
date:   Decision Analysis
output:
  beamer_presentation:
 #   theme: "metropolis"
    theme: "AnnArbor"
    colortheme: "dolphin"
    fonttheme: "structuresmallcapsserif"
    toc: true
    #toc_depth: 3
    slide_level: 3
    fig_width: 3.5
    fig_height: 3
    fig_caption: true
   # html_document:
   #  toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


```{r make_beamer_slides, include=FALSE, eval= FALSE}
library(rmarkdown)

# See documentation at: https://rdrr.io/cran/rmarkdown/man/beamer_presentation.html
# and at: https://bookdown.org/yihui/rmarkdown/beamer-presentation.html
# and at: https://rdrr.io/cran/rmarkdown/man/render.html

render("", beamer_presentation(
  toc = FALSE,
  slide_level = NULL,
  number_sections = FALSE,
  incremental = FALSE,
  fig_width = 10,
  fig_height = 7,
  fig_crop = TRUE,
  fig_caption = TRUE,
  dev = "pdf",
  df_print = "default",
  theme = "default",
  colortheme = "default",
  fonttheme = "default",
  highlight = "default",
  template = "default",
  keep_tex = FALSE,
  keep_md = FALSE,
  latex_engine = "pdflatex",
  citation_package = c("none", "natbib", "biblatex"),
  self_contained = TRUE,
  includes = NULL,
  md_extensions = NULL,
  pandoc_args = NULL
)
```


```{r load packages, echo=FALSE, include=FALSE}
library(here)
```


### Beginnings: Probabilistic forecasting

```{r, out.width='40%', fig.align='center', fig.show = 'hold'}
knitr::include_graphics(here('slides','graphics','Completing_the_forecast.jpg'))
```

### 

```{r, out.width='70%', fig.align='full', fig.show = 'hold', fig.cap='Communication of forecast information during the Red River Flood of 1997 in Grand Forks, North Dakota'}
knitr::include_graphics(here('slides','graphics','Red_river_flood_1997.png'))
```

### The promise: data-driven decision making

Data science hype: "Better information $\rightarrow$ Better decisions!"

*Claim:* That's wrong. 

Data-driven decision-making also requires complementary analytics and products: 

 * *Prediction* : calibration of error, $\rightarrow$ *probabilistic* forecasts
 
 * *Optimization* : application-specific models and tools, attention to user objectives
 
 * *Visualization/communication* : intelligence *actionable* in terms of user's decision problem

### Realizing the promise of data-driven decision-making

On prediction, data science gallops along: machine learning, classification, prediction, inference$\ldots$

*Claim:* The promise of data science to empower data-driven decision-making lags its potential, because of insufficient focus on *complementary* analytics:

 * Rigorous quantification of *uncertainty* and *error* in outputs of predictive models
 * Accurate formal representation of decision problems -- including decision-maker's objectives and tolerance for risk
 * Appropriate use of optimization techniques 
 * Visualizations or other products customized to decision contexts
 
 

*Goal:* Identify good *actions*, conditional on predictions made with error 


## The Cloud Hunter's Problem

### Meet the Cloud Hunter

The Cloud Hunter is an atmospheric scientist.

The Cloud Hunter wants to collect data from inside *liquid boundary layer clouds*.

```{r, out.width='50%', fig.align='center'}
knitr::include_graphics(here('slides','graphics','ARM_with_boundary_layer_clouds.jpg'))
```

That takes aircraft. Which are expensive.

### The Cloud Hunter's Decision Problem

The Cloud Hunter’s Problem concerns how to allocate a fixed budget of flight hours between dates over the course of a field season. 

Fly/No-fly decisions must be made 1 day ahead, based on imperfect day-ahead forecasts of whether conditions are good or bad for collecting required data.



###

#### Current decision-making process:

```{r, out.width='70%', fig.align='center'}
knitr::include_graphics(here('slides','graphics','scientists_arguing.png'))
```

###

#### Proposed decision-making process:

```{r, out.width='100%', fig.align='center'}
knitr::include_graphics(here('slides','graphics','The_Creation_of_Adam.png'))
```



## Formal model of the Cloud Hunter's decision problem



### Model setup: Conditions for data collection over the course of the field season

$D$ : length of the field season in days

$d = D, \ldots, 1$ : index of dates

$X_d$ : quality of conditions for data collection: 

 * $X_d = 1$ if conditions on date $d$ are good, 0 otherwise
 * Each $X_d$ a binary random state variable, i.e., a Bernoulli trial

A field season is a particular realization $x_D, \ldots, x_1$ of the stochastic process 
$X_D,\ldots, X_1$.

Will assume the $X_d$ are independent and identically distributed (i.i.d.). 

 * Assumption not actually required, but keeps things simpler and clearer.

Vector notation: $\bf{X} =$$< X_D, \ldots, X_1>$ denotes the stochastic process; $\bf{x} =$$< x_D, \ldots, x_1>$ denotes a particular realization.

### Model setup: Decisions, resource constraints

$F \leq D$ : number of flights in the Cloud Hunter’s budget. 

$f = F, \ldots, 1$ : index of flights remaining in budget

$a_d$ :  binary control variables ("actions")

* $a_d = 1$ iff they opt to fly on date $d$, 0 otherwise

$\bf{a} =$$< a_D, \ldots, a_1>$ : actions chosen on dates $d = D, \ldots, 1$

Resource constraint: $\sum_d a_d \leq F$.

(Assume flights left over at the end of the season have no residual value.)

### Payoffs and objectives

*Payoffs*: For a given sequence of choices $\bf{a}$ and realizations $\bf{x}$, the realized amount of data collected $U$ is given by 
$$U = \mathbf{a \cdot x} =\sum_d a_d x_d$$.

*Decision-maker's objective*: Choose a fly/no-fly decision rule to maximize data collected in expection, subject to the resource constraint on total allowable flights:

Choose $\bf{a}$ to $max_{\bf{a}} = E[\bf{a} \cdot \bf{X}]$, subject to $\sum_d a_d \leq F$.

\textbf{Important:} This is a *substantive assumption* about the decision-maker's goals.

  * Models a decision-maker with a high tolerance for *risk*. 


### Forecasts

Decision taken on basis of a day-ahead forecast.

Before taking each decision, decision-maker receives a forecast signal $s_d \in \mathbb{S}$.

Calibration: map this signal to a probability of good conditions:

$$p(s) =  \Pr\{X_d = 1 | s_d = s\}$$.

(Will assume stationarity.)

### Distribution of forecast signals

More than one day ahead, don't know which forecast signals $s \in \mathbb{S}$ will be received.

But, *do* know the the likelihood of receiving different signals.

$\pi(s)$ : probability that forecasting system will generate signal $s$. 

$\pi(\cdot)$ defines a probability distribution over the set $\mathbb{S}$ of possible forecast signals.

### The task of the decision analyst

Given this set-up, the job of the decision analyst is to devise an *optimal decision rule* $a^* = a(d,f |p)$ that delivers a recommended action---fly or no-fly---as a function of 

 * $d$ the number of days left in the field season, 
 * $f$ the number of flights left in the budget, and 
 * $p(s)$ the forecast probability that a flight today would be successful.
 
A decision rule $a(\cdot)$ is deemed optimal if its consistent application maximizes in expectation the yield of successful flights realized from a given budget $F$.

### Comment

This is a challenge of *intertemporal optimization*: each choice $a_d$ alters the expected payoffs for subsequent decisions. 

Need to use tools of optimization that account for this intertemporal structure.

*Dynamic programming* turns out to be the right tool for the job.

## Optimization via dynamic programming

### Intertemporal optimization via dynamic programming

Basic idea: break the decision problem into two pieces: (i) the next day's decision, and (ii) the rest of the field season after that.

Assume you've got the right answer (!). Given that this answer is optimal, derive the properties that solution must have.

Solve via backward induction.

### 

Suppose an optimal decision rule $a(d, f | s)$ has been found. 

Let $V(d, f)$ denote the expected number of successes that would be realized from repeated application of this rule, starting from initial conditions $<d, f>$. 

By construction, $V(\cdot)$ equals the maximand of the decision-maker's objective function, beginning from these initial conditions, under the substitution $a = a(d, f | s)$:

$$V(d,f) = E^{\pi} \left[ \sum_{i = d,\ldots, 1} a(i,f_i | s_i) \cdot X_i \right]$$
where the expectation is taken over the probability distribution of all possible sequences of forecast signals (determined by $\pi$), and where $f_i$ denotes the number of flights remaining on date $i$ when the optimal program is followed.

###

$V(d,f)$ called the *value function* for this problem.

Because $a(\cdot)$ is assumed to be optimal, $V(\cdot)$ must satisfy a particular recursive relationship:
$$ V(d,f) = E^{\pi} \left[ a^*_d \cdot X_d  + V(d-1, f- a^*_d) \right]$$
where $a^*_d = a(d,f | s_d)$ is the optimal decision.

###

Once the forecast signal $s_d$ is received, $a^*$ will be chosen optimally:

  * If $a^* = 1$, then $V(d,f | s_d) = E \left[X_d | s_d \right]  + V(d-1, f- 1)$.
  * If $a^* = 0$, then $V(d,f | s_d) = V(d-1, f)$.

Since $V(\cdot)$ is by construction a maximum, we must have:
$$V(d,f | s_d) = \max \{ E \left[ X_d | s_d \right]  + V(d-1, f- 1), V(d-1, f) \}$$
               
$=  \max \{ p(s_d) + V(d-1, f- 1), V(d-1, f) \}$
               
###

This formula implies the optimal decision rule: $a^* = 1$ ("fly") only if

$$ p(s_d) \geq V(d-1, f) -V(d-1, f- 1)$$
i.e., when the expected payoff of the current day's opportunity exceeds the loss in marginal cost associated with arriving tomorrow with one fewer flight in the bank.

Call $p(s_d)$ the *hurdle probability*.

###

```{r, out.width='50%', fig.align='center', fig.cap='Graphical representation of the decision algorithm.'}
knitr::include_graphics(here('slides','graphics','dynamic_programming_lattice.png'))
```


## Probabilistic forecasting of favorable conditions using self-organizing maps

###

```{r, out.width='50%', fig.align='center', fig.cap='6 X 4 SOM grid for relative humidity profiles'}
knitr::include_graphics(here('slides','graphics','SOM_grid_literal.png'))
```

###

```{r, out.width='50%', fig.align='center', fig.cap='Conditional probability distribution of SOM state realizations following a forecast of SOM state 1'}
knitr::include_graphics(here('slides','graphics','conditional_distribution_SOM_state_1.png'))
```

###

```{r, out.width='50%', fig.align='center', fig.cap='Estimated probabilities of good conditions for data collection, as a function of day-ahead SOM forecast'}
knitr::include_graphics(here('slides','graphics','SOM_grid_calibrated.png'))
```

## Results

###

```{r, out.width='75%', fig.align='center', fig.cap='Computed values for the value function $V(d, f)$'}
knitr::include_graphics(here('slides','graphics','value_function.png'))
```


Dark line : simulated sequence of flight decisions

  * Diagonal movements = fly dates, horizontal movements  = no-fly dates 

###

```{r, out.width='50%', fig.align='center', fig.cap='Results: the algorithm’s simulated performance during 2009 field season, compared with realized performance of heuristic decision procedure.'}
knitr::include_graphics(here('slides','graphics','algorithm_performance.png'))
```


The algorithm achieves a 21% increase in the number of successful flights.

###

```{r, out.width='50%', fig.align='center', fig.cap='Summary of outcomes'}
knitr::include_graphics(here('slides','graphics','hits_and_misses.png'))
```



Successes are flights launched on days with good conditions. 

Type I errors are decisions to fly only to find no clouds.

Type II errors are decisions to stand down only to find that the desired conditions existed.



