---
title: 'Forecasting and the Value of Information'
 # subtitle: ''
author: "Arthur Small"
institute: "Spring 2020" 
date:   SYS 6014 Decision Analysis
output:
  beamer_presentation:
 #   theme: "metropolis"
    theme: "AnnArbor"
    colortheme: "dolphin"
    fonttheme: "structuresmallcapsserif"
    toc: false
    #toc_depth: 3
    slide_level: 3
    fig_width: 3.5
    fig_height: 3
    fig_caption: true
    
   # html_document:
   #  toc: true
   
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r load packages, echo=FALSE, include=FALSE}
library(here)
```


## Evaluating forecasting systems: Scoring rules

### Forecast evaluation

*Forecast evaluation* involves analyzing how well your forecasting system generates predictions that match observations.

Elements of a forecast evaluation:

  * Data: a sequence of *matched ordered pairs* of forecasts + corresponding observations

  * A *scoring rule*: A formula that maps the sequence of forecasts and observations to a summary metric of the quality of the forecasting system
  
Important issues:

  * *Measurement error in observations*: In some cases, verifying observations may not be known with perfect precision.
  
  * *Scoring rules

### Q: "How good is your forecasting system?"

How would you answer?

Different ways to measure forecast quality:

  * Correlation between forecasts and verifying observations
  * ...


### But is it really?



## The Value of Information

###

Idea: Score your forecasting system in terms of how much value it adds to your decision system.






